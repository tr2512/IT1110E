{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MNIST training examples: 60000\n",
      "Number of MNIST test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of MNIST training examples: {}\".format(len(mnist_train)))\n",
    "print(\"Number of MNIST test examples: {}\".format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default image shape: torch.Size([1, 28, 28])\n",
      "Reshaped image shape: torch.Size([28, 28])\n",
      "The label for this image: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick out the 4th (0-indexed) example from the training set\n",
    "image, label = mnist_train[3]\n",
    "\n",
    "# Plot the image\n",
    "print(\"Default image shape: {}\".format(image.shape))\n",
    "image = image.reshape([28,28])\n",
    "print(\"Reshaped image shape: {}\".format(image.shape))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# Print the label\n",
    "print(\"The label for this image: {}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the minibatch of images: torch.Size([100, 1, 28, 28])\n",
      "Shape of the minibatch of labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "data_train_iter = iter(train_loader)\n",
    "images, labels = data_train_iter.next()\n",
    "\n",
    "print(\"Shape of the minibatch of images: {}\".format(images.shape))\n",
    "print(\"Shape of the minibatch of labels: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input x: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "x = images.view(-1, 28*28)\n",
    "print(\"The shape of input x: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weights W\n",
    "W = torch.randn(784, 10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "\n",
    "# Initialize bias b as 0s\n",
    "b = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0277,  0.2020, -0.1585,  0.9000,  0.1090, -0.7819,  0.4943, -0.1411,\n",
      "         0.1503,  0.1505], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py[0] from equation: tensor([0.0816, 0.1027, 0.0716, 0.2064, 0.0936, 0.0384, 0.1376, 0.0729, 0.0975,\n",
      "        0.0976], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "py_eq = torch.exp(y) / torch.sum(torch.exp(y), dim=1, keepdim=True)\n",
    "print(\"py[0] from equation: {}\".format(py_eq[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy from equation: 2.371337413787842\n"
     ]
    }
   ],
   "source": [
    "cross_entropy_eq = torch.mean(-torch.log(py_eq)[range(labels.shape[0]),labels])\n",
    "print(\"cross entropy from equation: {}\".format(cross_entropy_eq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28e414e8f0f455ebf6bb9e874fd070b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9480a6516d74939b7bf5e68cc1caff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9025999903678894\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "## Training\n",
    "# Initialize parameters\n",
    "W = torch.randn(784, 10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "b = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD([W,b], lr=0.1)\n",
    "\n",
    "# Iterate through train set minibatchs \n",
    "for images, labels in tqdm(train_loader):\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x = images.view(-1, 28*28)\n",
    "    y = torch.matmul(x, W) + b\n",
    "    cross_entropy = F.cross_entropy(y, labels)\n",
    "    # Backward pass\n",
    "    cross_entropy.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "## Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = torch.matmul(x, W) + b\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "    \n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
